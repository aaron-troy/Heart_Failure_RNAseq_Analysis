{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dfb5bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'infomap', 'karateclub', 'graph_tool', 'wurlitzer'}\n",
      "Note: to be able to use all overlapping methods, you need to install some additional packages:  {'karateclub', 'ASLPAw'}\n",
      "Note: to be able to use all bipartite methods, you need to install some additional packages:  {'infomap', 'wurlitzer'}\n"
     ]
    }
   ],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import scipy.stats as ss\n",
    "import os\n",
    "import itertools\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm \n",
    "from random import sample\n",
    "from random import normalvariate\n",
    "from cdlib import algorithms\n",
    "\n",
    "# Minimum size for the final Leiden communities\n",
    "MIN_COM_SIZE = 8\n",
    "\n",
    "# Nice for easily estimating how long things will take to run\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "# Graph class from Omics-Integrator. See repo here: https://github.com/fraenkel-lab/OmicsIntegrator2\n",
    "import graph\n",
    "\n",
    "# Tools for completing the PCSF analsysis \n",
    "import pcsftools as pt \n",
    "\n",
    "# Path for the input data\n",
    "data_path = os.path.dirname(os.getcwd()) + \"/data\"\n",
    "\n",
    "# Path for references\n",
    "ref_path = os.path.dirname(os.getcwd()) + \"/ref/\"\n",
    "\n",
    "# Path to for a map between STRING ID and gene names\n",
    "map_path = ref_path + \"human.name_2_string.txt\"\n",
    "\n",
    "# Grab the prepped protein protein interaction network (PPI)\n",
    "ppi  = pd.read_csv(ref_path + \"prepped_STRING_9606.protein.links.v11.5.txt\", sep = \"\\t\")\n",
    "ppi = ppi[['protein1', 'protein2', 'cost']]\n",
    "ppi = ppi.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a630c081",
   "metadata": {},
   "source": [
    "#### We're now ready to run the Prize Collecting Steiner Forest algo using the provided PPI and the prizes from our data. The problem is defined as follows: \n",
    "\n",
    "$$\n",
    "\\text{Find } T(n,e) \\Rightarrow \\text{ }\\psi(T) = \\text{min}\\bigg[b \\sum_{n \\notin N_T} p(n) + \\sum_{e \\in E_T} c^*(e)\\bigg]\n",
    "$$\n",
    "\n",
    "with $c^*(e)$ defined as:\n",
    "\n",
    "$$ c^*(e) = \\begin{cases} \n",
    "      c(e) + \\frac{d_x d_y}{d_x d_y  + (N - d_x  - 1) (N - d_y - 1)} 10^g & \\text{if } e \\in E \\\\\n",
    "      w & \\text{if } e \\in \\{\\{r,s\\} : s \\in S\\}\n",
    "   \\end{cases}\n",
    "$$\n",
    "\n",
    "This requires a few parameters that will determine to the cost of each possible subnetwork is computed: \n",
    "\n",
    "- Parameter w: penalizes the inclusion of edges linking terminals to dummy node. High w implies more Steiner nodes in the final network\n",
    "\n",
    "- Parameter b: penalize the exclusion of prize holding terminal nodes. Higher b implies more prize holding terminal nodes in the final network\n",
    "\n",
    "- Parameter g: Penalize the inclusion of hub genes with excessive connectivy. For exploratory analsysis in search of the overal network strucutre, no need to include this, set to 0. \n",
    "\n",
    "Clearly, we want ensure the solutions that we find are robust, and thus not particularly sensitive to changes in the parameters. To check this, we'll run PCSF for many discrete combinations of b and w that span a reasonable range. We can then compute the Jaccard similarity of the resulting subgraphs and confirm that small changes in these parameters don't redacially alter the solution produced. First, let's get the seeds, or terminals, we want to include in the PCSF solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4609120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutoff values to include DEGs as seeds\n",
    "p_cut_DEG = 1e-6\n",
    "log2_cut = 1\n",
    "\n",
    "# Cutoff values to include TFs as seeds\n",
    "p_cut_TF = 0.05\n",
    "score_cut = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0aab67",
   "metadata": {},
   "source": [
    "### Prep for PCSF in pEF and rEF by selecting only DEGs and TFs that meet the above criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390363ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in both the DEGs and TFs\n",
    "DE_df = pd.read_csv(data_path + '/cov_adj_DEGs_deseq.csv', sep = ',')\n",
    "TF_df = pd.read_csv(data_path + '/z_score_TF_enrichment.csv', sep = ',')\n",
    "\n",
    "# Convert to string ID\n",
    "DE_df['string_id'] = pt.convert_to_string_id(DE_df['external_gene_name'], map_path)\n",
    "TF_df['string_id'] = pt.convert_to_string_id(TF_df['external_gene_name'], map_path)\n",
    "\n",
    "# Filter DEGs to differntially expressed, large l2FC for HFpEF and HFrEF\n",
    "pEF_DEGs = DE_df[DE_df['padj_PEF'] < p_cut_DEG]\n",
    "rEF_DEGs = DE_df[DE_df['padj_REF'] < p_cut_DEG]\n",
    "pEF_DEGs = pEF_DEGs[np.abs(pEF_DEGs['log2FoldChange_PEF']) > log2_cut]\n",
    "rEF_DEGs = rEF_DEGs[np.abs(rEF_DEGs['log2FoldChange_REF']) > log2_cut]\n",
    "\n",
    "# Do the same for TFs\n",
    "pEF_TFs = TF_df[TF_df['p_adj_PEF'] < p_cut_TF]\n",
    "rEF_TFs = TF_df[TF_df['p_adj_REF'] < p_cut_TF]\n",
    "pEF_TFs = pEF_TFs[np.abs(pEF_TFs['score_PEF']) > score_cut]\n",
    "rEF_TFs = rEF_TFs[np.abs(rEF_TFs['score_REF']) > score_cut]\n",
    "\n",
    "# Take only those with STRING ids\n",
    "pEF_DEGs = pEF_DEGs[pEF_DEGs['string_id'].str.contains(\"9606.\")]\n",
    "rEF_DEGs = rEF_DEGs[rEF_DEGs['string_id'].str.contains(\"9606.\")]\n",
    "pEF_TFs = pEF_TFs[pEF_TFs['string_id'].str.contains(\"9606.\")]\n",
    "rEF_TFs = rEF_TFs[rEF_TFs['string_id'].str.contains(\"9606.\")]\n",
    "\n",
    "# Rescale the TF seed scores to match the DEGs\n",
    "tf_scale_factor_pEF = np.abs(max(DE_df.z_score_PEF)) / np.abs(max(TF_df.z_score_PEF))\n",
    "tf_scale_factor_rEF = np.abs(max(DE_df.z_score_REF)) / np.abs(max(TF_df.z_score_REF))\n",
    "\n",
    "# Take only DEGs for which we don't have a TF value \n",
    "pEF_DEGs = pEF_DEGs[~(pEF_DEGs.external_gene_name.isin(pEF_TFs.external_gene_name))]\n",
    "rEF_DEGs = rEF_DEGs[~(rEF_DEGs.external_gene_name.isin(rEF_TFs.external_gene_name))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f03b1",
   "metadata": {},
   "source": [
    "### Build seeds dataframe for PCSF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59f57e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pEF_seeds = pd.DataFrame({'name':pd.concat([pEF_DEGs.string_id, pEF_TFs.string_id]),\n",
    "                          'prize' : pd.concat([np.abs(pEF_DEGs.z_score_PEF), (np.abs(pEF_TFs.z_score_PEF) * tf_scale_factor_pEF)]), \n",
    "                              'score' : pd.concat([pEF_DEGs.z_score_PEF, (pEF_TFs.z_score_PEF * tf_scale_factor_pEF)]),\n",
    "                              'gene' : pd.concat([pEF_DEGs.external_gene_name, pEF_TFs.external_gene_name])}).sort_values(by = 'prize', ascending = False)\n",
    "pEF_seeds = pEF_seeds[pEF_seeds['name'].str.contains(\"9606.\")]\n",
    "\n",
    "\n",
    "rEF_seeds = pd.DataFrame({'name':pd.concat([rEF_DEGs.string_id, rEF_TFs.string_id]),\n",
    "                          'prize' : pd.concat([np.abs(rEF_DEGs.z_score_REF), (np.abs(rEF_TFs.z_score_REF) * tf_scale_factor_rEF)]), \n",
    "                              'score' : pd.concat([rEF_DEGs.z_score_REF, (rEF_TFs.z_score_REF * tf_scale_factor_rEF)]),\n",
    "                              'gene' : pd.concat([rEF_DEGs.external_gene_name, rEF_TFs.external_gene_name])}).sort_values(by = 'prize', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ee2cc",
   "metadata": {},
   "source": [
    "#### Save the seeds with today's date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b637a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pEF_seeds.to_csv(data_path + \"pEF_seeds_\" + str(date.today()) + \".csv\", index = False)\n",
    "#rEF_seeds.to_csv(data_path + \"rEF_seeds_\" + str(date.today()) + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e68485",
   "metadata": {},
   "source": [
    "#### Prior to sensitivity analsyis, we need to do some basic math to determine what parameter ranges are acceptable. \n",
    "\n",
    "In the case of b, we want the cost of exlcuding a seed node to at least exceed the maximum edge cost. Otherwise, the algo has insentive to exclude thingds we've measured (seeds) in favor of things that haven't been measured (Steiner nodes).\n",
    "\n",
    "Recall, the edge cost is defined as:\n",
    "\n",
    "$$ c^*(e) = \\begin{cases} \n",
    "      c(e) + \\frac{d_x d_y}{d_x d_y  + (N - d_x  - 1) (N - d_y - 1)} 10^g & \\text{if } e \\in E \\\\\n",
    "      w & \\text{if } e \\in \\{\\{r,s\\} : s \\in S\\}\n",
    "   \\end{cases} $$\n",
    "\n",
    "This suggests we require $b \\geq 1$ to ensure a large number of seeds are retained in the solution.\n",
    "\n",
    "To determine a range for $w$ to use in thge SA, notice that selecting $w$ too low will result in a trivial solution with all seed nodes connected solely to the root dummy node, and thus isolated in the final solution. Conversely, $w$ set too high will prevent the inclusion of any connections to the root node, and produce a fully-connected solution. SA should thus be conducted using a range of $w$ that spans the distribution of costs for shortest paths between all seed nodes.  \n",
    "\n",
    "To do this, apply Dijkstra's alorithm to all combinations of seed genes with edges costs given by the PCSF algorithm.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b45ed580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.0 %\n",
      "Progress: 0.0052186619350798455 %\n",
      "Progress: 0.010437323870159691 %\n",
      "Progress: 0.015655985805239536 %\n",
      "Progress: 0.020874647740319382 %\n",
      "Progress: 0.026093309675399228 %\n",
      "Progress: 0.03131197161047907 %\n",
      "Progress: 0.03653063354555892 %\n",
      "Progress: 0.041749295480638764 %\n",
      "Progress: 0.04696795741571861 %\n",
      "Progress: 0.052186619350798456 %\n",
      "Progress: 0.0574052812858783 %\n",
      "Progress: 0.06262394322095814 %\n",
      "Progress: 0.06784260515603799 %\n",
      "Progress: 0.07306126709111783 %\n",
      "Progress: 0.07827992902619768 %\n",
      "Progress: 0.08349859096127753 %\n",
      "Progress: 0.08871725289635737 %\n",
      "Progress: 0.09393591483143722 %\n",
      "Progress: 0.09915457676651707 %\n",
      "Progress: 0.10437323870159691 %\n",
      "Progress: 0.10959190063667676 %\n",
      "Progress: 0.1148105625717566 %\n",
      "Progress: 0.12002922450683645 %\n",
      "Progress: 0.12524788644191628 %\n",
      "Progress: 0.13046654837699614 %\n",
      "Progress: 0.13568521031207598 %\n",
      "Progress: 0.14090387224715584 %\n",
      "Progress: 0.14612253418223567 %\n",
      "Progress: 0.15134119611731553 %\n",
      "Progress: 0.15655985805239536 %\n",
      "Progress: 0.16177851998747522 %\n",
      "Progress: 0.16699718192255505 %\n",
      "Progress: 0.17221584385763491 %\n",
      "Progress: 0.17743450579271475 %\n",
      "Progress: 0.18265316772779458 %\n",
      "Progress: 0.18787182966287444 %\n",
      "Progress: 0.19309049159795427 %\n",
      "Progress: 0.19830915353303413 %\n",
      "Progress: 0.20352781546811397 %\n",
      "Progress: 0.20874647740319383 %\n",
      "Progress: 0.21396513933827366 %\n",
      "Progress: 0.21918380127335352 %\n",
      "Progress: 0.22440246320843335 %\n",
      "Progress: 0.2296211251435132 %\n",
      "Progress: 0.23483978707859304 %\n",
      "Progress: 0.2400584490136729 %\n",
      "Progress: 0.24527711094875274 %\n",
      "Progress: 0.25049577288383257 %\n",
      "Progress: 0.25571443481891243 %\n",
      "Progress: 0.2609330967539923 %\n",
      "Progress: 0.26615175868907215 %\n",
      "Progress: 0.27137042062415195 %\n",
      "Progress: 0.2765890825592318 %\n",
      "Progress: 0.2818077444943117 %\n",
      "Progress: 0.2870264064293915 %\n",
      "Progress: 0.29224506836447134 %\n",
      "Progress: 0.2974637302995512 %\n",
      "Progress: 0.30268239223463106 %\n",
      "Progress: 0.30790105416971086 %\n",
      "Progress: 0.3131197161047907 %\n",
      "Progress: 0.3183383780398706 %\n",
      "Progress: 0.32355703997495044 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-502636595e04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpEF_path_costs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_path_costs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpEF_seeds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mppi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_prog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampled_proportion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrEF_path_costs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_path_costs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrEF_seeds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mppi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_prog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampled_proportion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Bioinformatics\\Network Analysis of HFpEF\\Hahn_FGN_Analysis\\pcsf_python\\pcsftools.py\u001b[0m in \u001b[0;36mget_path_costs\u001b[1;34m(seeds, adj_list, print_prog, sampled_proportion)\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# Tr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m             \u001b[0mpath_costs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhome\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdijkstra_path_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhome\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"cost\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNetworkXNoPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNodeNotFound\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[1;31m# If home/dest are not connected, continue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py\u001b[0m in \u001b[0;36mdijkstra_path_length\u001b[1;34m(G, source, target, weight)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_weight_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dijkstra\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py\u001b[0m in \u001b[0;36m_dijkstra\u001b[1;34m(G, source, weight, pred, paths, cutoff, target)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     \"\"\"\n\u001b[1;32m--> 759\u001b[1;33m     return _dijkstra_multisource(\n\u001b[0m\u001b[0;32m    760\u001b[0m         \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m     )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py\u001b[0m in \u001b[0;36m_dijkstra_multisource\u001b[1;34m(G, sources, weight, pred, paths, cutoff, target)\u001b[0m\n\u001b[0;32m    835\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG_succ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 837\u001b[1;33m             \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    838\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(u, v, data)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_multigraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pEF_path_costs = pt.get_path_costs(pEF_seeds.name, ppi, print_prog = True, sampled_proportion = 0.1)\n",
    "rEF_path_costs = pt.get_path_costs(rEF_seeds.name, ppi, print_prog = False, sampled_proportion = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32812898",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pEF_path_costs.values(), alpha = 0.5)\n",
    "plt.hist(rEF_path_costs.values(), alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c444d819",
   "metadata": {},
   "source": [
    "#### Set up bounds and sampling density for the sampled parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11863272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter g: Penalize the inclusion of hub genes with excessive connectivy. For exploratory analsysis in search of the overal network strucutre, no need to include this, set to 0. \n",
    "g = 0\n",
    "\n",
    "#Parameter w: penalizes the inclusion of edges linking terminals to dummy node. High w implies more Steiner nodes in the final network\n",
    "set_w = [round(w, 2) for w in np.linspace(0.2,4,10)]\n",
    "\n",
    "#Parameter b: penalize the exclusion of prize holding terminal nodes. Higher b implies more prize holding terminal nodes in the final network\n",
    "set_b = np.linspace(1, 20, 10)\n",
    "\n",
    "paramCombs = list(itertools.product(set_w, set_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b68e0f0",
   "metadata": {},
   "source": [
    "#### Generate th PCSF solutions using different combinations, no noise\n",
    "\n",
    "This may take awhile, depending on size of the parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9d053",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sensiResults_pEF = {}\n",
    "sensiResults_rEF = {}\n",
    "\n",
    "n = 0\n",
    "\n",
    "for (w, b) in paramCombs:\n",
    "    \n",
    "    print(\"Progress:\", (n * 100) / len(paramCombs), \"%\")\n",
    "    \n",
    "    n = n+1\n",
    "    \n",
    "    params = {\"w\": w, \"b\": b, \"g\": 0, \"edge_noise\": 0, \"dummy_mode\": \"terminals\", \"seed\": 0, \"skip_checks\": False}\n",
    "    \n",
    "    # HFpEF\n",
    "    \n",
    "    sensiResults_pEF[(g,w,b)] = pt.run_pcsf(pEF_seeds, ppi, params, time = False, addAttribs = False)\n",
    "\n",
    "    # HFrEF\n",
    "    \n",
    "    sensiResults_rEF[(g,w,b)] = pt.run_pcsf(rEF_seeds, ppi, params, time = False, addAttribs = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e793637a",
   "metadata": {},
   "source": [
    "#### View a sensitivity heat map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pEF_sensi_mat = pt.make_solution_similarity_matrix(sensiResults_pEF)\n",
    "\n",
    "sns.heatmap(pEF_sensi_mat, cmap = \"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e7191",
   "metadata": {},
   "outputs": [],
   "source": [
    "rEF_sensi_mat = pt.make_solution_similarity_matrix(sensiResults_rEF)\n",
    "\n",
    "sns.heatmap(rEF_sensi_mat, cmap = \"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affad98e",
   "metadata": {},
   "source": [
    "#### Assemble consensus networks\n",
    "Having selected a region of staibillity, let's inject some edge noise that will make the solution stochastic.\n",
    "We can then prune the final solution to only edges that appears in the majoirty of solutions (e.g. 95% or better). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa895a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define the number of random solutions to generate\n",
    "reps = 100\n",
    "\n",
    "params = {\"w\": 2, \n",
    "          \"b\": 10, \n",
    "          \"g\": 0, \n",
    "          \"edge_noise\": 0.1,\n",
    "          \"dummy_mode\": \"terminals\",\n",
    "          \"seed\": 0,\n",
    "          \"skip_checks\": False}\n",
    "\n",
    "#First, HFpEF\n",
    "pcsfGraph_pEF = graph.Graph(ppi, params)\n",
    "pcsfGraph_pEF.prepare_prizes(pEF_seeds)\n",
    "randomForest_pEF, _ = pcsfGraph_pEF.randomizations(noisy_edges_reps=reps, random_terminals_reps=0)\n",
    "\n",
    "#Next, HFrEF\n",
    "pcsfGraph_rEF = graph.Graph(ppi, params)\n",
    "pcsfGraph_rEF.prepare_prizes(rEF_seeds)\n",
    "randomForest_rEF, _ = pcsfGraph_rEF.randomizations(noisy_edges_reps=reps, random_terminals_reps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca626da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a confidence threshold for nodes to be retained\n",
    "confThresh = 0.9\n",
    "\n",
    "#Remove nodes that don't meet the required confidence\n",
    "consensusForest_pEF = randomForest_pEF.copy()\n",
    "consensusForest_pEF.remove_nodes_from(\n",
    "    [node for node, freq in nx.get_node_attributes(consensusForest_pEF, 'robustness').items() if freq < confThresh]\n",
    ")\n",
    "\n",
    "#Remove nodes that don't meet the required confidence\n",
    "consensusForest_rEF = randomForest_rEF.copy()\n",
    "consensusForest_rEF.remove_nodes_from(\n",
    "    [node for node, freq in nx.get_node_attributes(consensusForest_rEF, 'robustness').items() if freq < confThresh]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d76e087",
   "metadata": {},
   "source": [
    "#### Apply the Leiden algorithm to identify communities, using the edge confidence as weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb6d6dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pEF_coms = algorithms.leiden(consensusForest_pEF, weights = 'confidence')\n",
    "pEF_com_list = pEF_coms.communities\n",
    "\n",
    "rEF_coms = algorithms.leiden(consensusForest_rEF, weights = 'confidence')\n",
    "rEF_com_list = rEF_coms.communities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a28fa",
   "metadata": {},
   "source": [
    "#### Discard communities below some threshold size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(pEF_com_list[-1]) < MIN_COM_SIZE:\n",
    "    pEF_com_list.pop()\n",
    "    \n",
    "while len(rEF_com_list[-1]) < MIN_COM_SIZE:\n",
    "    rEF_com_list.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66b5802",
   "metadata": {},
   "source": [
    "#### We can annotate known drug targets in the resulting communities using a list of approved FDA targets\n",
    "\n",
    "Retrieve the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d17b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "fda_targets = pd.read_csv(ref_path + '//protein_class_FDA.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af08b08e",
   "metadata": {},
   "source": [
    "#### Setup a routine for plotting the Leiden communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506d99db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_leiden_com(com, graph, seeds, mapPath, drug_targets = None):\n",
    "\n",
    "    #Community subgraph\n",
    "    com_graph = graph.subgraph(com)\n",
    "\n",
    "    # As a dataframe with gene names\n",
    "    com_details = pt.get_network_details(com_graph)\n",
    "    com_details['gene'] = pt.convert_to_gene_symbol(com_details.index, map_path)\n",
    "    com_details['score'] = 0\n",
    "\n",
    "    # Get scores for seed nodes in the community\n",
    "    com_seeds = list(set(com_details.index) & set(seeds.name))\n",
    "    for s in com_seeds:\n",
    "        com_details.loc[s, 'score'] = float(seeds[seeds['name'] == s]['score'])\n",
    "\n",
    "    # Setup colors as a function of seed node score.\n",
    "    scores = list(com_details.score)\n",
    "    norm = mpl.colors.Normalize(vmin=min(scores), vmax=max(scores))\n",
    "    m = cm.ScalarMappable(norm=norm, cmap=cm.coolwarm)\n",
    "    \n",
    "    # Keep steiner nodes grey\n",
    "    steinerColor = [0.6] * 3 + [1]\n",
    "    colors = m.to_rgba(com_details['score'])\n",
    "    \n",
    "    # Add color to details dataframe\n",
    "    com_details['color'] = colors = [steinerColor if scores[i] == 0.0 else colors[i] for i in range(len(scores))]\n",
    "\n",
    "    # Find nodes that are druggable, if a list is passed\n",
    "    if drug_targets != None:\n",
    "        \n",
    "        # Separate druggable from non-druggable nodes\n",
    "        targets = list(set(drug_targets) & set(com_details.gene))\n",
    "        druggable = com_details[com_details['gene'].isin(targets)]\n",
    "        non_druggable = com_details[~com_details['gene'].isin(targets)]\n",
    "        \n",
    "        # Plot the community\n",
    "        \n",
    "        # First just the structure\n",
    "        plt.figure(figsize = (12,12))\n",
    "        pos = nx.layout.spring_layout(com_graph)\n",
    "        nx.draw_networkx_edges(com_graph, pos)\n",
    "        # Add non-druggable nodes\n",
    "        nx.draw_networkx_nodes(com_graph, pos, nodelist = non_druggable.index, \n",
    "                              node_color = non_druggable.color)\n",
    "        # Add druggable nodes\n",
    "        nx.draw_networkx_nodes(com_graph, pos, nodelist = druggable.index,\n",
    "                              node_color = druggable.color, node_shape='d')\n",
    "        # Add labels\n",
    "        nx.draw_networkx_labels(com_graph, pos, font_size = 14, labels = dict(zip(com_details.index, com_details.gene)),verticalalignment = 'baseline', horizontalalignment = 'left')\n",
    "    else:\n",
    "        # If there's no drug list, just plot everything at once\n",
    "        nx.draw_spring(com_graph, node_color = colors, font_size = 14, labels = dict(zip(com_details.index, com_details.gene)))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4224e7c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for com in pEF_com_list:\n",
    "    plot_leiden_com(com, consensusForest_pEF, pEF_seeds, map_path, drug_targets = list(fda_targets.Gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e15ed11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for com in rEF_com_list:\n",
    "    plot_leiden_com(com, consensusForest_rEF, rEF_seeds, map_path, drug_targets = list(fda_targets.Gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9e14f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
